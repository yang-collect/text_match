{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "train_path='lcqmc/train.tsv'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "with open(train_path,'r',encoding='utf-8') as f :\r\n",
    "    lines=f.readlines()\r\n",
    "    text_a=[]\r\n",
    "    text_b=[]\r\n",
    "    label=[]\r\n",
    "    for i,line in enumerate(lines):\r\n",
    "        if i==0:\r\n",
    "            continue\r\n",
    "        line=line.split('\\t')\r\n",
    "        text_a.append(line[0])\r\n",
    "        text_b.append(line[1])\r\n",
    "        label.append(line[2])\r\n",
    "print(text_a[0])\r\n",
    "print(text_b[0])\r\n",
    "print(label[0])\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "喜欢打篮球的男生喜欢什么样的女生\n",
      "爱打篮球的男生喜欢什么样的女生\n",
      "1\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "\r\n",
    "model_path=r'C:\\Users\\wie\\Documents\\项目\\model_file\\ernie-1.0'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "from transformers import BertModel,BertTokenizer\r\n",
    "model=BertModel.from_pretrained(model_path)\r\n",
    "tokenizer=BertTokenizer.from_pretrained(model_path)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at C:\\Users\\wie\\Documents\\项目\\model_file\\ernie-1.0 were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "import jieba"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "sorted(map(len,text_b),reverse=True)[:10]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[27, 27, 25, 24, 24, 24, 24, 24, 24, 24]"
      ]
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "source": [
    "sorted(map(len,text_a),reverse=True)[:10]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[26, 26, 24, 24, 23, 23, 23, 23, 22, 22]"
      ]
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "source": [
    "list(jieba.cut(text_a[1]))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['英雄', '联盟', '什么', '英雄', '最好']"
      ]
     },
     "metadata": {},
     "execution_count": 100
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "encode_a=tokenizer(text_a[1],text_b[1],truncation='longest_first',padding='max_length',max_length=20,return_tensors='pt')\r\n",
    "# encode_b=tokenizer(list(jieba.cut(text_b[0])),return_tensors='pt')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "encode_a['input_ids'].shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([1, 20])"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "encode_a['input_ids'].shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "encode_a['attention_mask'].shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([1, 20])"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "source": [
    "text_a[1]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'英雄联盟什么英雄最好'"
      ]
     },
     "metadata": {},
     "execution_count": 132
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "source": [
    "torch.nn.utils.rnn.pad_sequence(text_a,max_length=50,)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[   1,  514,  904,  387, 1251,  614,  356,  514,  904,  134,  170,    2]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "metadata": {},
     "execution_count": 133
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "source": [
    "encode_a"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[   1,  514,  904,  387, 1251,  614,  356,  514,  904,  134,  170,    2]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "metadata": {},
     "execution_count": 134
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "source": [
    "encode_a['input_ids'].shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([1, 12])"
      ]
     },
     "metadata": {},
     "execution_count": 135
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "source": [
    "encode_a['input_ids']"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[   1, 1022,    2,    0],\n",
       "        [   1,    9,    2,    0],\n",
       "        [   1, 1568,    2,    0],\n",
       "        [   1,  127,    2,    0],\n",
       "        [   1,   47,  501,    2],\n",
       "        [   1,   69,  334,    2],\n",
       "        [   1,    5,    2,    0]])"
      ]
     },
     "metadata": {},
     "execution_count": 86
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "source": [
    "tokenizer.decode(encode_a['input_ids'][0]).split()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['[CLS]', '英', '雄', '联', '盟', '什', '么', '英', '雄', '最', '好', '[SEP]']"
      ]
     },
     "metadata": {},
     "execution_count": 102
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "source": [
    "out_a=model(**encode_a)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "source": [
    "c,d=out_a"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "source": [
    "c"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'last_hidden_state'"
      ]
     },
     "metadata": {},
     "execution_count": 113
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "source": [
    "out_a[0]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[[ 1.5285, -0.1840, -0.5873,  ...,  0.2267, -1.2869,  0.5957],\n",
       "         [ 0.5399, -0.0453, -0.3098,  ...,  0.5722, -0.2438, -3.7611],\n",
       "         [ 0.1686, -0.5325, -0.2617,  ...,  0.0855,  0.2366, -2.2502],\n",
       "         ...,\n",
       "         [ 0.3396, -0.1772, -0.3614,  ...,  0.4463,  0.5605, -1.2392],\n",
       "         [ 1.3477, -0.2689, -0.5477,  ...,  0.2529,  0.7380, -0.6643],\n",
       "         [ 1.5285, -0.1840, -0.5873,  ...,  0.2267, -1.2869,  0.5957]]],\n",
       "       grad_fn=<NativeLayerNormBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 110
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "out_b=model(**encode_b)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "out_a.last_hidden_state.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([1, 18, 768])"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "out_b.last_hidden_state.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([1, 17, 768])"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "import torch.nn.functional as F"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "source": [
    "import torch"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "source": [
    "a=torch.rand((5,16,512))\r\n",
    "b=torch.randint(0, 20, (5,16,512))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "source": [
    "b"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[[12, 14, 14,  ..., 14, 11, 11],\n",
       "         [ 4, 16, 11,  ...,  3, 18,  7],\n",
       "         [ 4,  9,  4,  ..., 12, 17,  7],\n",
       "         ...,\n",
       "         [ 0, 17,  2,  ...,  7, 16,  4],\n",
       "         [ 7, 10,  3,  ...,  2, 19, 18],\n",
       "         [11, 17, 13,  ...,  9, 13,  5]],\n",
       "\n",
       "        [[ 4, 19, 11,  ..., 14,  9,  0],\n",
       "         [ 1, 16,  2,  ...,  2, 19, 13],\n",
       "         [18,  4,  4,  ..., 10, 15,  4],\n",
       "         ...,\n",
       "         [16, 14,  2,  ...,  4,  2,  2],\n",
       "         [ 3,  6, 19,  ...,  6,  9,  7],\n",
       "         [18,  4,  1,  ...,  3, 19,  8]],\n",
       "\n",
       "        [[ 3,  8, 16,  ...,  3, 13, 17],\n",
       "         [14,  2,  2,  ..., 13,  1, 17],\n",
       "         [11, 14, 11,  ...,  1,  1, 16],\n",
       "         ...,\n",
       "         [17,  6,  2,  ...,  8, 11,  3],\n",
       "         [15,  5,  3,  ..., 16,  9, 12],\n",
       "         [11, 16,  5,  ...,  7, 11, 18]],\n",
       "\n",
       "        [[13,  0, 15,  ..., 17,  3, 12],\n",
       "         [ 4, 16,  0,  ...,  9, 11,  4],\n",
       "         [17,  1, 19,  ..., 19, 11, 19],\n",
       "         ...,\n",
       "         [13,  3, 16,  ...,  7, 11,  6],\n",
       "         [16,  3, 14,  ..., 17, 16, 12],\n",
       "         [14,  0,  4,  ..., 19, 12,  1]],\n",
       "\n",
       "        [[ 4, 17,  4,  ..., 14, 15,  2],\n",
       "         [10,  4,  6,  ..., 16,  2, 16],\n",
       "         [13,  7, 19,  ..., 19,  5, 10],\n",
       "         ...,\n",
       "         [18,  9,  0,  ...,  9,  1,  9],\n",
       "         [ 8,  4, 17,  ..., 11,  7, 14],\n",
       "         [15,  0, 14,  ..., 16, 19, 15]]])"
      ]
     },
     "metadata": {},
     "execution_count": 124
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "source": [
    "F.cosine_similarity(a,b,dim=-1).shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([5, 16])"
      ]
     },
     "metadata": {},
     "execution_count": 126
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "source": [
    "l=torch.nn.Linear(10,2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "source": [
    "y=torch.randint(0,2,(5,1))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "source": [
    "l(a)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[-0.7463, -0.0829],\n",
       "        [-0.5700,  0.0317],\n",
       "        [-0.4670, -0.0753],\n",
       "        [-0.6752,  0.1018],\n",
       "        [-0.5743, -0.1608]], grad_fn=<AddmmBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 69
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.9",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "41ef8895d486fc720bbf7e715661c6d0ed9c052c03840bbb42df10b3effdc11d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}